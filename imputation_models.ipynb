{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"]=\":4096:8\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import importlib\n",
    "from sklearn.impute import SimpleImputer\n",
    "import utils\n",
    "import data\n",
    "import modelMP\n",
    "import modelSDAE\n",
    "import helper_train_MP\n",
    "import helper_train_SDAE\n",
    "import helper_train_MP_GAN\n",
    "import helper_noise\n",
    "\n",
    "importlib.reload(utils)\n",
    "importlib.reload(data)\n",
    "importlib.reload(modelMP)\n",
    "importlib.reload(helper_train_MP)\n",
    "importlib.reload(modelSDAE)\n",
    "importlib.reload(helper_train_SDAE)\n",
    "importlib.reload(helper_noise)\n",
    "importlib.reload(helper_train_MP_GAN)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "torch.random.manual_seed(1)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "def dae_noise(x):\n",
    "    return torch.rand_like(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dcon = {\n",
    "    'dataset': 'FashionMNIST', # one of 'MNIST', 'FashionMNIST', 'CIFAR10'\n",
    "    'noise_mechanism': 'mnar', # missingness mechanism ('mcar', 'mar', 'mnar', 'patch', 'patches', 'threshold', 'special_mar', 'special_mnar_log', 'special_mnar_self_log', 'special_mnar_quant', 'fixed_patch')\n",
    "    'na_obs_percentage': 0.4, # the number of observations that have missing values\n",
    "    'replacement': 0, # what value is plugged in for missing values in the observations with missing values (number or 'uniform')\n",
    "    'noise_level': 0.2, # the percentage of missing values per observation (share of features that are missing)\n",
    "    'download': False,\n",
    "    'regenerate': True,\n",
    "    'device': device,\n",
    "\n",
    "\n",
    "    # for noise_mechanism 'patches'\n",
    "    'patch_size_axis': 5, # size of the patch in the x and y direction\n",
    "\n",
    "    # for noise_mechanism MAR and MNAR\n",
    "    'randperm_cols': False, # whether to shuffle the columns of the data matrix before applying the noise mechanism\n",
    "    'average_missing_rates': 'normal', # can be 'uniform', 'normal' or a list/tuple/tensor of length no. of features, determines how the missingness rates are generated\n",
    "    # if uniform, noise_level is used as mean for uniform distribution and impossible values are clipped to the interval [0,1] --> noise_level != exact missingness rate in mask\n",
    "    # if normal, noise_level is ignored and the options below apply\n",
    "    'chol_eps': 1e-6, # epsilon for the cholesky decomposition (epsilon*I is added to the covariance matrix to make it positive definite)\n",
    "    'sigmoid_offset': 0.05, # offset for the sigmoid function applied to the average missing rates generated by MultivariateNormal\n",
    "    'sigmoid_k': 10, # steepness of sigmoid\n",
    "\n",
    "    # for MNAR only\n",
    "    'dependence': 'simple_unobserved', # can be 'simple_unobserved', 'complex_unobserved', 'unobserved_and_observed'\n",
    "\n",
    "    ### for the 'special_*' missingness generators only\n",
    "    # all of them\n",
    "    'p': 0.8,\n",
    "\n",
    "    # MAR_mask\n",
    "    'p_obs': 0.6,\n",
    "\n",
    "    # MNAR_mask_logistic\n",
    "    # p as a before\n",
    "    'p_params': 0.7,\n",
    "    'exclude_inputs': False,\n",
    "\n",
    "    # MNAR_mask_quantiles\n",
    "    # p and p_params as before\n",
    "    'q': 0.2,\n",
    "    'cut': 'both', # can be 'upper', 'lower', 'both'\n",
    "    'MCAR': False, # whether MCAR is added on the non-MNAR mask\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "data_without_nas_1 = data.ImputationDatasetGen(config=dcon, missing_vals=False)\n",
    "data_with_nas_1 = data.ImputationDatasetGen(config=dcon, missing_vals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcon0 = {\n",
    "    'architecture': 'encoder_model_dae',\n",
    "    'loss': 'full', # must be full otherwise error\n",
    "    'epochs': 10,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 3e-4,\n",
    "    'lr_decay': False,\n",
    "    'gamma': 2e-4,\n",
    "    'step_size': 45,\n",
    "    'layer_dims_enc': [784, 2000, 700],\n",
    "    'layer_dims_dec': [700, 2000, 784],\n",
    "    'device': device,\n",
    "    'relu': True,\n",
    "    'image': True,\n",
    "    'noise_model': dae_noise,\n",
    "    'corruption_share': 0.2, # level of the dropout noise that is used for training the DAE\n",
    "    'mask_between_epochs': 'equal', # equal or random, determines the scope of the random generator that is passed to the mask bernoulli sampling function\n",
    "    'additional_noise': 0, # does not apply here\n",
    "}\n",
    "\n",
    "tcon0 = {\n",
    "    'new_training': 1,\n",
    "    'log': 0,\n",
    "    'save_model': 1,\n",
    "    'img_index': 4, # index of the image to be plotted\n",
    "    'activations': 1,\n",
    "    'device': device,\n",
    "    'train_val_test_split': [0.8, 0.2, 0]\n",
    "}\n",
    "\n",
    "if 'MNIST' in dcon['dataset']:\n",
    "    mcon0['layer_dims_enc'][0] = 784\n",
    "    mcon0['layer_dims_dec'][-1] = 784\n",
    "elif 'CIFAR10' in dcon['dataset']:\n",
    "    mcon0['layer_dims_enc'][0] = 1024\n",
    "    mcon0['layer_dims_dec'][-1] = 1024\n",
    "    \n",
    "nona_train_loader_0 = DataLoader(data.DatasetWithSplits(data_without_nas_1, 'train', tcon0['train_val_test_split']), batch_size=mcon0['batch_size'], shuffle=True)\n",
    "nona_val_loader_0 = DataLoader(data.DatasetWithSplits(data_without_nas_1, 'validation', tcon0['train_val_test_split']), batch_size=mcon0['batch_size'], shuffle=False)\n",
    "\n",
    "model_autoencoder = modelSDAE.SyntheticDenoisingAutoEncoder(noise_model=dae_noise, layer_dims_enc=mcon0['layer_dims_enc'], layer_dims_dec=mcon0['layer_dims_dec'], relu=mcon0['relu'], image=mcon0['image']).to(device)\n",
    "loss_fn_autoencoder = nn.MSELoss(reduction='none')\n",
    "optimizer_autoencoder = torch.optim.Adam(model_autoencoder.parameters(), lr=mcon0['learning_rate'])\n",
    "scheduler_autoencoder = StepLR(optimizer_autoencoder, step_size=mcon0['step_size'], gamma=mcon0['gamma'])\n",
    "print(model_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_train_SDAE.train_imputation_model(model=model_autoencoder, encoder=None, loss_fn=loss_fn_autoencoder, optimizer=optimizer_autoencoder, scheduler=scheduler_autoencoder,\n",
    "                                    dcon=dcon, mcon=mcon0, tcon=tcon0,\n",
    "                                    train_dataloader=nona_train_loader_0, validation_dataloader=nona_val_loader_0,\n",
    "                                    noise_model=dae_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an Encoder model\n",
    "last_autoencoder = sorted(os.listdir(f'models/{mcon0[\"architecture\"]}/{dcon[\"dataset\"]}/{dcon[\"noise_mechanism\"]}'))[-1]\n",
    "last_autoencoder_model_path = os.path.join(f'models/{mcon0['architecture']}/{dcon['dataset']}/{dcon[\"noise_mechanism\"]}', last_autoencoder)\n",
    "checkpoint_autoencoder = torch.load(last_autoencoder_model_path)\n",
    "\n",
    "model_autoencoder = modelSDAE.SyntheticDenoisingAutoEncoder(noise_model=dae_noise, \n",
    "                                                            layer_dims_enc=checkpoint_autoencoder['mcon']['layer_dims_enc'], layer_dims_dec=checkpoint_autoencoder['mcon']['layer_dims_dec'],\n",
    "                                                            relu=checkpoint_autoencoder['mcon']['relu'], image=checkpoint_autoencoder['mcon']['image']).to(device)\n",
    "model_autoencoder.load_state_dict(checkpoint_autoencoder['model_state_dict'])\n",
    "model_autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcon = {\n",
    "    'architecture': 'mask_pred_mlp', # one of 'mask_pred_mlp', 'mask_pred_vae', 'mask_pred_gan', 'mask_pred_cgan'\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 3e-4,\n",
    "    'lr_decay': False,\n",
    "    'gamma': 2e-4,\n",
    "    'step_size': 45,\n",
    "    'layer_dims': [784, 2000, 2000, 2000, 784],\n",
    "    'dropout': 0.5,\n",
    "    'device': device,\n",
    "    'relu': True,\n",
    "    'image': True,\n",
    "    'encoder': last_autoencoder_model_path,\n",
    "\n",
    "    # for mask_pred_vae\n",
    "    'layer_dims_enc': [784, 1000, 2],\n",
    "    'layer_dims_dec': [2, 1000, 784],\n",
    "\n",
    "    # for mask_pred_gan\n",
    "    'layer_dims_gen': [10+1024, 128, 1024],\n",
    "    'layer_dims_disc': [2*1024, 128, 1],\n",
    "    'lr_gen': 0.002,\n",
    "    'lr_disc': 0.0002,\n",
    "    'betas': (0.9, 0.999),\n",
    "    \n",
    "}\n",
    "\n",
    "tcon = {\n",
    "    'new_training': 1,\n",
    "    'log': 0,\n",
    "    'save_model': 1,\n",
    "    'img_index': 4, # index of the image to be plotted\n",
    "    'activations': 1,\n",
    "    'device': device,\n",
    "    'train_val_test_split': [0.8, 0.2, 0]\n",
    "}\n",
    "\n",
    "if 'MNIST' in dcon['dataset']:\n",
    "    mcon['layer_dims'][0] = checkpoint_autoencoder['mcon']['layer_dims_enc'][-1]\n",
    "    mcon['layer_dims'][-1] = 784\n",
    "    mcon['layer_dims_enc'][0] = checkpoint_autoencoder['mcon']['layer_dims_enc'][-1]\n",
    "    mcon['layer_dims_dec'][-1] = 784\n",
    "elif 'CIFAR10' in dcon['dataset']:\n",
    "    mcon['layer_dims'][0] = checkpoint_autoencoder['mcon']['layer_dims_enc'][-1]\n",
    "    mcon['layer_dims'][-1] = 1024\n",
    "    mcon['layer_dims_enc'][0] = checkpoint_autoencoder['mcon']['layer_dims_enc'][-1]\n",
    "    mcon['layer_dims_dec'][-1] = 1024\n",
    "\n",
    "nona_train_loader_1 = DataLoader(data.DatasetWithSplits(data_without_nas_1, 'train', tcon['train_val_test_split']), batch_size=mcon['batch_size'], shuffle=True)\n",
    "nona_val_loader_1 = DataLoader(data.DatasetWithSplits(data_without_nas_1, 'validation', tcon['train_val_test_split']), batch_size=mcon['batch_size'], shuffle=False)\n",
    "nona_test_loader_1 = DataLoader(data.DatasetWithSplits(data_without_nas_1, 'test', tcon['train_val_test_split']), batch_size=mcon['batch_size'], shuffle=False)\n",
    "\n",
    "na_train_loader_1 = DataLoader(data.DatasetWithSplits(data_with_nas_1, 'train', tcon['train_val_test_split']), batch_size=mcon['batch_size'], shuffle=True)\n",
    "na_val_loader_1 = DataLoader(data.DatasetWithSplits(data_with_nas_1, 'validation', tcon['train_val_test_split']), batch_size=mcon['batch_size'], shuffle=False)\n",
    "na_test_loader_1 = DataLoader(data.DatasetWithSplits(data_with_nas_1, 'test', tcon['train_val_test_split']), batch_size=mcon['batch_size'], shuffle=False)\n",
    "\n",
    "if 'mlp' in mcon['architecture']:\n",
    "    model_mp = modelMP.MaskPredMLP(layer_dims=mcon['layer_dims'], dropout=mcon['dropout'], relu=mcon['relu'], image=mcon['image']).to(device)\n",
    "elif 'vae' in mcon['architecture']:\n",
    "    model_mp = modelMP.MaskPredVAE(layer_dims_enc=mcon['layer_dims_enc'], layer_dims_dec=mcon['layer_dims_dec'], dropout=mcon['dropout'],\n",
    "                                relu=mcon['relu'], image=mcon['image'], device=device).to(device)\n",
    "elif 'gan' in mcon['architecture']:\n",
    "    model_mp = modelMP.MaskPredGAN(layer_dims_gen=mcon['layer_dims_gen'], layer_dims_disc=mcon['layer_dims_disc'], dropout=mcon['dropout'],\n",
    "                                relu=mcon['relu'], image=mcon['image']).to(device)\n",
    "else:\n",
    "    raise ValueError('Invalid architecture')\n",
    "\n",
    "\n",
    "if 'mlp' in mcon['architecture'] or 'vae' in mcon['architecture']:\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model_mp.parameters(), lr=mcon['learning_rate'])\n",
    "    scheduler = StepLR(optimizer, step_size=mcon['step_size'], gamma=mcon['gamma'])\n",
    "elif 'gan' in mcon['architecture']:\n",
    "    optimizer_gen = torch.optim.Adam(model_mp.generator.parameters(), lr=mcon['lr_gen'], betas=mcon['betas'])\n",
    "    optimizer_disc = torch.optim.SGD(model_mp.discriminator.parameters(), lr=mcon['lr_disc'])\n",
    "    scheduler_gen = StepLR(optimizer_gen, step_size=mcon['step_size'], gamma=mcon['gamma'])\n",
    "    scheduler_disc = StepLR(optimizer_disc, step_size=mcon['step_size'], gamma=mcon['gamma'])\n",
    "print(model_mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train (and save) model\n",
    "if not 'gan' in mcon['architecture']:\n",
    "    helper_train_MP.train_model(model=model_mp, encoder=model_autoencoder.encoder, loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler,\n",
    "                                        dcon=dcon, mcon=mcon, tcon=tcon,\n",
    "                                        train_dataloader=na_train_loader_1, validation_dataloader=na_val_loader_1\n",
    "                                        )\n",
    "    helper_train_MP.test(dataloader=na_val_loader_1, model=model_mp, encoder=model_autoencoder.encoder, loss_fn=loss_fn, tcon=tcon, dcon=dcon, mcon=mcon)\n",
    "elif 'gan' in mcon['architecture']:\n",
    "    helper_train_MP_GAN.train_model(model=model_mp, optimizer_gen=optimizer_gen, optimizer_disc=optimizer_disc, \n",
    "                                    scheduler_gen=scheduler_gen, scheduler_disc=scheduler_disc,\n",
    "                                    dcon=dcon, mcon=mcon, tcon=tcon,\n",
    "                                    train_na_dataloader=DataLoader(data_with_nas_1, batch_size=mcon['batch_size'], shuffle=True),\n",
    "                                    train_nona_dataloader=DataLoader(data_without_nas_1, batch_size=mcon['batch_size'], shuffle=True),\n",
    "                                    train_both_loader=DataLoader(data.DatasetZipped(data_without_nas_1, data_with_nas_1), batch_size=mcon['batch_size'], shuffle=True),\n",
    "                                    test_na_dataloader=DataLoader(data_with_nas_1, batch_size=mcon['batch_size'], shuffle=False),\n",
    "                                    test_nona_dataloader=DataLoader(data_without_nas_1, batch_size=mcon['batch_size'], shuffle=False)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Synthetic Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load noise model (mask prediction model) and Encoder from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_noise_model = sorted(os.listdir(f'models/{mcon[\"architecture\"]}/{dcon[\"dataset\"]}/{dcon[\"noise_mechanism\"]}'))[-1]\n",
    "last_noise_model_path = os.path.join(f'models/{mcon['architecture']}/{dcon['dataset']}/{dcon[\"noise_mechanism\"]}', last_noise_model)\n",
    "checkpoint = torch.load(last_noise_model_path)\n",
    "\n",
    "noise_model = modelMP.MaskPredMLP(layer_dims=checkpoint['mcon']['layer_dims'], dropout=checkpoint['mcon']['dropout'],\n",
    "                                  relu=checkpoint['mcon']['relu'], \n",
    "                                  image=checkpoint['mcon']['image']).to(device)\n",
    "noise_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "noise_model.eval()\n",
    "\n",
    "# load an encoder model\n",
    "last_autoencoder = sorted(os.listdir(f'models/{mcon0[\"architecture\"]}/{dcon[\"dataset\"]}/{dcon[\"noise_mechanism\"]}'))[-1]\n",
    "last_autoencoder_model_path = os.path.join(f'models/{mcon0['architecture']}/{dcon['dataset']}/{dcon[\"noise_mechanism\"]}', last_autoencoder)\n",
    "checkpoint_autoencoder = torch.load(last_autoencoder_model_path)\n",
    "\n",
    "model_autoencoder = modelSDAE.SyntheticDenoisingAutoEncoder(noise_model=dae_noise, \n",
    "                                                            layer_dims_enc=checkpoint_autoencoder['mcon']['layer_dims_enc'], layer_dims_dec=checkpoint_autoencoder['mcon']['layer_dims_dec'],\n",
    "                                                            relu=checkpoint_autoencoder['mcon']['relu'], image=checkpoint_autoencoder['mcon']['image']).to(device)\n",
    "model_autoencoder.load_state_dict(checkpoint_autoencoder['model_state_dict'])\n",
    "model_autoencoder.eval()\n",
    "dcon2 = dcon.copy()\n",
    "dcon2['replacement'] = 0 # the value that is inserted with the noise process for the training of the DAE (on the fully observed data) and for the test set that is used to evaluate the DAE\n",
    "dcon2['regenerate'] = True if dcon2['replacement'] != dcon['replacement'] else False\n",
    "\n",
    "mcon2 = {\n",
    "    'architecture': 'synthetic_dae',\n",
    "    'loss': 'full', # full or focused\n",
    "    'epochs': 15,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 3e-4,\n",
    "    'lr_decay': False,\n",
    "    'gamma': 2e-4,\n",
    "    'step_size': 45,\n",
    "    'layer_dims_enc': [784, 2000, 2000, 2000],\n",
    "    'layer_dims_dec': [2000, 2000, 2000, 784],\n",
    "    'device': device,\n",
    "    'relu': True,\n",
    "    'image': True,\n",
    "    'noise_model': last_noise_model_path,\n",
    "    'encoder': last_autoencoder_model_path,\n",
    "    'corruption_share': -1, # the share of features that are corrupted in the training of the DAE, -1 means that all missingness generated by the MP model is used\n",
    "    'mask_between_epochs': 'equal', # equal or random, determines the scope of the random generator that is passed to the mask bernoulli sampling function\n",
    "    'additional_noise': 0, # the share of additional noise that is added to the data during training\n",
    "}\n",
    "if 'MNIST' in dcon2['dataset']:\n",
    "    mcon2['layer_dims_enc'][0] = 784\n",
    "    mcon2['layer_dims_dec'][-1] = 784\n",
    "elif 'CIFAR10' in dcon2['dataset']:\n",
    "    mcon2['layer_dims_enc'][0] = 1024\n",
    "    mcon2['layer_dims_dec'][-1] = 1024\n",
    "\n",
    "tcon2 = {\n",
    "    'new_training': 1,\n",
    "    'log': 1,\n",
    "    'save_model': 1,\n",
    "    'img_index': 10, # index of the image to be plotted\n",
    "    'activations': 1,\n",
    "    'device': device,\n",
    "    'train_val_test_split': [0.8, 0.2, 0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "data_without_nas_2 = data.ImputationDatasetGen(config=dcon2, missing_vals=False)\n",
    "data_with_nas_2 = data.ImputationDatasetGen(config=dcon2, missing_vals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nona_train_loader_2 = DataLoader(data.DatasetWithSplits(data_without_nas_2, 'train', tcon2['train_val_test_split']), batch_size=mcon2['batch_size'], shuffle=True)\n",
    "nona_val_loader_2 = DataLoader(data.DatasetWithSplits(data_without_nas_2, 'validation', tcon2['train_val_test_split']), batch_size=mcon2['batch_size'], shuffle=False)\n",
    "nona_test_loader_2 = DataLoader(data.DatasetWithSplits(data_without_nas_2, 'test', tcon2['train_val_test_split']), batch_size=mcon2['batch_size'], shuffle=False)\n",
    "\n",
    "na_test_loader_2 = DataLoader(data.DatasetWithSplits(data_with_nas_2, 'test', [0, 0, 1]), batch_size=mcon2['batch_size'], shuffle=False) #here shuffle false, because it is only used for testing\n",
    "model_sdae = modelSDAE.SyntheticDenoisingAutoEncoder(noise_model=noise_model, layer_dims_enc=mcon2['layer_dims_enc'], layer_dims_dec=mcon2['layer_dims_dec'], relu=mcon2['relu'], image=mcon2['image']).to(device)\n",
    "loss_fn_sdae = nn.MSELoss(reduction='none')\n",
    "optimizer_sdae = torch.optim.Adam(model_sdae.parameters(), lr=mcon2['learning_rate'])\n",
    "scheduler_sdae = StepLR(optimizer_sdae, step_size=mcon2['step_size'], gamma=mcon2['gamma'])\n",
    "print(model_sdae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_train_SDAE.train_imputation_model(model=model_sdae, encoder=model_autoencoder.encoder, loss_fn=loss_fn_sdae, optimizer=optimizer_sdae, scheduler=scheduler_sdae,\n",
    "                                    dcon=dcon2, mcon=mcon2, tcon=tcon2,\n",
    "                                    train_dataloader=nona_train_loader_2, validation_dataloader=nona_val_loader_2, test_dataloader=na_test_loader_2,\n",
    "                                    noise_model=noise_model)\n",
    "helper_train_SDAE.test(dataloader=na_test_loader_2, model=model_sdae, loss_fn=loss_fn_sdae, dcon=dcon2, mcon=mcon2, tcon=tcon2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downstream Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_imputation_model = sorted(os.listdir(f'models/{mcon2[\"architecture\"]}/{dcon2[\"dataset\"]}/{dcon2[\"noise_mechanism\"]}'))[-1]\n",
    "last_imputation_model_path = os.path.join(f'models/{mcon2['architecture']}/{dcon2['dataset']}/{dcon2[\"noise_mechanism\"]}', last_imputation_model)\n",
    "checkpoint_imputation = torch.load(last_imputation_model_path)\n",
    "\n",
    "imputation_model = modelSDAE.SyntheticDenoisingAutoEncoder(noise_model=noise_model, \n",
    "                                                           layer_dims_enc=checkpoint_imputation['mcon']['layer_dims_enc'], layer_dims_dec=checkpoint_imputation['mcon']['layer_dims_dec'],\n",
    "                                                           relu=checkpoint_imputation['mcon']['relu'], \n",
    "                                                           image=checkpoint_imputation['mcon']['image']).to(device)\n",
    "imputation_model.load_state_dict(checkpoint_imputation['model_state_dict'])\n",
    "imputation_model.eval()\n",
    "\n",
    "imputed_data = imputation_model(data_with_nas_2.data.to(device))\n",
    "imputed_targets = data_with_nas_2.labels\n",
    "\n",
    "full_data = torch.cat((data_without_nas_2.data.cpu(), imputed_data.cpu()), dim=0).detach()\n",
    "full_targets = torch.cat((data_without_nas_2.labels.cpu(), imputed_targets.cpu()), dim=0).detach()\n",
    "\n",
    "utils.softmaxRegression(full_data, full_targets, num_classes=10, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark DAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dae_noise(x):\n",
    "    return torch.rand_like(x)\n",
    "dcon3 = dcon2.copy()\n",
    "dcon3['replacement'] = 0\n",
    "dcon3['regenerate'] = True\n",
    "\n",
    "mcon3 = {\n",
    "    'architecture': 'benchmark_dae',\n",
    "    'loss': 'full', # full or focused\n",
    "    'epochs': 5,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 3e-4,\n",
    "    'lr_decay': False,\n",
    "    'gamma': 2e-4,\n",
    "    'step_size': 45,\n",
    "    'layer_dims_enc': [784, 2000, 2000],\n",
    "    'layer_dims_dec': [2000, 2000, 784],\n",
    "    'device': device,\n",
    "    'relu': True,\n",
    "    'image': True,\n",
    "    'noise_model': dae_noise,\n",
    "    'corruption_share': 0.2, # the share of features that are corrupted in the training of the DAE\n",
    "    'mask_between_epochs': 'random', # (DOES NOT APPLY to benchmark_DAE)\n",
    "    'additional_noise': 0, # the share of additional noise that is added to the data during training\n",
    "}\n",
    "if 'MNIST' in dcon3['dataset']:\n",
    "    mcon3['layer_dims_enc'][0] = 784\n",
    "    mcon3['layer_dims_dec'][-1] = 784\n",
    "elif 'CIFAR10' in dcon3['dataset']:\n",
    "    mcon3['layer_dims_enc'][0] = 1024\n",
    "    mcon3['layer_dims_dec'][-1] = 1024\n",
    "\n",
    "tcon3 = {\n",
    "    'new_training': 1,\n",
    "    'log': 0,\n",
    "    'save_model': 1,\n",
    "    'img_index': 10, # index of the image to be plotted\n",
    "    'activations': 1,\n",
    "    'device': device,\n",
    "    'train_val_test_split': [0.8, 0.2, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(1)\n",
    "data_without_nas_3 = data.ImputationDatasetGen(config=dcon3, missing_vals=False)\n",
    "data_with_nas_3 = data.ImputationDatasetGen(config=dcon3, missing_vals=True)\n",
    "nona_train_loader_3 = DataLoader(data.DatasetWithSplits(data_without_nas_3, 'train', tcon3['train_val_test_split']), batch_size=mcon3['batch_size'], shuffle=True)\n",
    "nona_val_loader_3 = DataLoader(data.DatasetWithSplits(data_without_nas_3, 'validation', tcon3['train_val_test_split']), batch_size=mcon3['batch_size'], shuffle=False)\n",
    "nona_test_loader_3 = DataLoader(data.DatasetWithSplits(data_without_nas_3, 'test', tcon3['train_val_test_split']), batch_size=mcon3['batch_size'], shuffle=False)\n",
    "\n",
    "na_test_loader_3 = DataLoader(data.DatasetWithSplits(data_with_nas_3, 'test', [0, 0, 1]), batch_size=mcon3['batch_size'], shuffle=False) #here shuffle false, because it is only used for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bdae = modelSDAE.SyntheticDenoisingAutoEncoder(noise_model=dae_noise, layer_dims_enc=mcon3['layer_dims_enc'], layer_dims_dec=mcon3['layer_dims_dec'], relu=mcon3['relu'], image=mcon3['image']).to(device)\n",
    "loss_fn_bdae = nn.MSELoss(reduction='none')\n",
    "optimizer_bdae = torch.optim.Adam(model_bdae.parameters(), lr=mcon3['learning_rate'])\n",
    "scheduler_bdae = StepLR(optimizer_bdae, step_size=mcon3['step_size'], gamma=mcon3['gamma'])\n",
    "print(model_bdae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_train_SDAE.train_imputation_model(model=model_bdae, encoder=None, loss_fn=loss_fn_bdae, optimizer=optimizer_bdae, scheduler=scheduler_bdae,\n",
    "                                    dcon=dcon3, mcon=mcon3, tcon=tcon3,\n",
    "                                    train_dataloader=nona_train_loader_3, validation_dataloader=nona_val_loader_3, test_dataloader=na_test_loader_3,\n",
    "                                    noise_model=dae_noise)\n",
    "helper_train_SDAE.test(dataloader=na_test_loader_3, model=model_bdae, loss_fn=loss_fn_bdae, dcon=dcon3, mcon=mcon3, tcon=tcon3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bdae.eval()\n",
    "imputed_data = model_bdae(data_with_nas_2.data.to(device).detach())\n",
    "imputed_targets = data_with_nas_2.labels\n",
    "\n",
    "full_data = torch.cat((data_without_nas_2.data.cpu(), imputed_data.cpu()), dim=0).detach()\n",
    "full_targets = torch.cat((data_without_nas_2.labels.cpu(), imputed_targets.cpu()), dim=0).detach()\n",
    "\n",
    "utils.softmaxRegression(full_data, full_targets, num_classes=10, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcon4 = {\n",
    "    'architecture': 'benchmark_vae',\n",
    "    'loss': 'full', # full or focused\n",
    "    'epochs': 1,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 3e-4,\n",
    "    'lr_decay': False,\n",
    "    'gamma': 2e-4,\n",
    "    'step_size': 45,\n",
    "    'layer_dims_enc': [784, 2000, 500],\n",
    "    'layer_dims_dec': [500, 2000, 784],\n",
    "    'device': device,\n",
    "    'relu': True,\n",
    "    'image': True,\n",
    "    'noise_model': None,\n",
    "    'corruption_share': 0.0, # (DOES NOT APPLY to benchmark_VAE)\n",
    "    'mask_between_epochs': 'random', # (DOES NOT APPLY to benchmark_VAE)\n",
    "    'additional_noise': 0, # the share of additional noise that is added to the data during training\n",
    "}\n",
    "if 'MNIST' in dcon3['dataset']:\n",
    "    mcon4['layer_dims_enc'][0] = 784\n",
    "    mcon4['layer_dims_dec'][-1] = 784\n",
    "elif 'CIFAR10' in dcon3['dataset']:\n",
    "    mcon4['layer_dims_enc'][0] = 1024\n",
    "    mcon4['layer_dims_dec'][-1] = 1024\n",
    "\n",
    "tcon4 = {\n",
    "    'new_training': 1,\n",
    "    'log': 0,\n",
    "    'save_model': 1,\n",
    "    'img_index': 10, # index of the image to be plotted\n",
    "    'activations': 1,\n",
    "    'device': device,\n",
    "    'train_val_test_split': [0.8, 0.2, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bvae = modelSDAE.ImputeVAE(layer_dims_enc=mcon4['layer_dims_enc'], layer_dims_dec=mcon4['layer_dims_dec'], relu=mcon4['relu'], image=mcon4['image']).to(device)\n",
    "loss_fn_bvae = nn.MSELoss(reduction='none')\n",
    "optimizer_bvae = torch.optim.Adam(model_bvae.parameters(), lr=mcon4['learning_rate'])\n",
    "scheduler_bvae = StepLR(optimizer_bvae, step_size=mcon4['step_size'], gamma=mcon4['gamma'])\n",
    "print(model_bvae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_train_SDAE.train_imputation_model(model=model_bvae, encoder=None, loss_fn=loss_fn_bvae, optimizer=optimizer_bvae, scheduler=scheduler_bvae,\n",
    "                                    dcon=dcon3, mcon=mcon4, tcon=tcon4,\n",
    "                                    train_dataloader=nona_train_loader_3, validation_dataloader=nona_val_loader_3, test_dataloader=na_test_loader_3,\n",
    "                                    noise_model=None)\n",
    "helper_train_SDAE.test(dataloader=na_test_loader_3, model=model_bvae, loss_fn=loss_fn_bvae, dcon=dcon3, mcon=mcon4, tcon=tcon4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bvae.eval()\n",
    "imputed_data = model_bvae(data_with_nas_2.data.to(device).detach())\n",
    "imputed_targets = data_with_nas_2.labels\n",
    "\n",
    "full_data = torch.cat((data_without_nas_2.data.cpu(), imputed_data.cpu()), dim=0).detach()\n",
    "full_targets = torch.cat((data_without_nas_2.labels.cpu(), imputed_targets.cpu()), dim=0).detach()\n",
    "\n",
    "utils.softmaxRegression(full_data, full_targets, num_classes=10, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Mode imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean imputation\n",
    "data_with_nas_as_nas = data_with_nas_2.data.clone()\n",
    "mask = data_with_nas_2.targets.clone()\n",
    "data_with_nas_as_nas[mask == 1] = float('nan')\n",
    "full_data = torch.cat((data_without_nas_2.data.cpu(), data_with_nas_as_nas.cpu()), dim=0).detach()\n",
    "full_targets = torch.cat((data_without_nas_2.labels.cpu(), data_with_nas_2.labels.cpu()), dim=0).detach()\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy='mean', copy=True).fit(full_data.cpu())\n",
    "full_data_imputed = torch.tensor(mean_imputer.transform(full_data)).float().to(device)\n",
    "ground_truth = data_with_nas_2.unmissing_data\n",
    "imputed_data = full_data_imputed[range(data_with_nas_as_nas.size(0)), :]\n",
    "\n",
    "mse = torch.sum(nn.MSELoss(reduction='none')(imputed_data.cpu(), ground_truth.cpu()) * (mask.cpu() == 1).float()) / torch.sum(mask.cpu())\n",
    "print(f'MSE: {mse}, RMSE: {torch.sqrt(mse)}')\n",
    "\n",
    "utils.softmaxRegression(full_data_imputed, full_targets, num_classes=10, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Simulated Noise Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('masked proportion: ', torch.sum(data_with_nas_1.targets)/torch.numel(data_with_nas_1.targets))\n",
    "\n",
    "cols = 10\n",
    "fig, ax = plt.subplots(3, cols)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "ax[0, 0].set_title('Original')\n",
    "ax[1, 0].set_title('Mask')\n",
    "ax[2, 0].set_title('Corrupted')\n",
    "\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "\n",
    "for i in range(cols):\n",
    "    ax[0, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_with_nas_1.unmissing_data, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[0, i].axis('off')\n",
    "    ax[1, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_with_nas_1.targets, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[1, i].axis('off')\n",
    "    ax[2, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_with_nas_1.data, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[2, i].axis('off')\n",
    "plt.suptitle('Patch Missingness')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learned Noise Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert path to relevant model below\n",
    "checkpoint = torch.load('models/mask_pred_mlp/CIFAR10/patch/modelJune18_12_14.pth')\n",
    "if 'mlp' in checkpoint['mcon']['architecture']:\n",
    "    noise_model_temp = modelMP.MaskPredMLP(layer_dims=checkpoint['mcon']['layer_dims'], relu=checkpoint['mcon']['relu'], \n",
    "                                        image=checkpoint['mcon']['image']).to(device)\n",
    "elif 'vae' in checkpoint['mcon']['architecture']:\n",
    "    noise_model_temp = modelMP.MaskPredVAE(layer_dims_enc=checkpoint['mcon']['layer_dims_enc'], layer_dims_dec=checkpoint['mcon']['layer_dims_dec'], \n",
    "                                        relu=checkpoint['mcon']['relu'], image=checkpoint['mcon']['image'], device=device).to(device)\n",
    "else:\n",
    "    raise ValueError('Architecture not supported')\n",
    "noise_model_temp.load_state_dict(checkpoint['model_state_dict'])\n",
    "noise_model_temp.eval()\n",
    "print(noise_model_temp)\n",
    "mask_probs = noise_model_temp(model_autoencoder.encoder(data_without_nas_1.data[range(100)].to(device)))\n",
    "mask = torch.bernoulli(mask_probs).detach()\n",
    "corrupted = data_without_nas_1.data[range(100)].clone()\n",
    "corrupted[mask == 1] = 0\n",
    "fig, ax = plt.subplots(3, 10)\n",
    "fig.set_figwidth(15)\n",
    "\n",
    "# give a title to the plot\n",
    "ax[0, 0].set_title('Original')\n",
    "ax[1, 0].set_title('Mask')\n",
    "ax[2, 0].set_title('Corrupted')\n",
    "\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "\n",
    "for i in range(10):\n",
    "    ax[0, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_without_nas_1.data, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[0, i].axis('off')\n",
    "    ax[1, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(mask, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[1, i].axis('off')\n",
    "    ax[2, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(corrupted, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[2, i].axis('off')\n",
    "# add title to plot\n",
    "plt.suptitle('Learned Missingness Patterns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Code for some of the Thesis Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Missingness Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 5\n",
    "fig, ax = plt.subplots(3, n_img, figsize=(10, 6))\n",
    "\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "\n",
    "for i in range(n_img):\n",
    "    ax[0, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_with_nas_1.unmissing_data, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[1, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_with_nas_1.targets, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "    ax[2, i].imshow(v2.ToDtype(torch.float32)(torch.unflatten(data_with_nas_1.data, dim=1, sizes=sizes))[i].cpu(), cmap='gray')\n",
    "\n",
    "# Labels for the y-axis\n",
    "y_labels = ['Ground Truth', 'Mask', 'Corrupted']\n",
    "\n",
    "# Apply y-axis labels to the leftmost column\n",
    "for i in range(3):\n",
    "    ax[i, 0].set_ylabel(y_labels[i], rotation=90, labelpad=8, fontsize=12, va='center', ha='center')\n",
    "    ax[i, 0].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks and labels except y-axis labels\n",
    "    for spine in ['top', 'right', 'bottom', 'left']:\n",
    "        ax[i, 0].spines[spine].set_visible(False)\n",
    "\n",
    "# Hide all other axes elements and labels\n",
    "for i in range(3):\n",
    "    for j in range(n_img):\n",
    "        ax[i, j].set_xticks([])  # Hide x-axis ticks\n",
    "        ax[i, j].set_yticks([])  # Hide y-axis ticks\n",
    "        ax[i, j].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks and labels\n",
    "        if j != 0:  # Hide spines for all but the leftmost column\n",
    "            for spine in ['top', 'right', 'bottom', 'left']:\n",
    "                ax[i, j].spines[spine].set_visible(False)\n",
    "\n",
    "# Add title to plot\n",
    "plt.suptitle('QMNAR Examples', fontsize=16, y=0.95, ha='center')\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Imputation Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_img = 25\n",
    "n_img = 5\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "reconstructed_sdae = torch.clip(model_sdae(data_with_nas_2.data.to(device)).detach(), 0, 1).cpu()[range(start_img, start_img+n_img)]\n",
    "reconstructed_bdae = torch.clip(model_bdae(data_with_nas_2.data.to(device)).detach(), 0, 1).cpu()[range(start_img, start_img+n_img)]\n",
    "reconstructed_bvae = torch.clip(model_bvae(data_with_nas_2.data.to(device)).detach(), 0, 1).cpu()[range(start_img, start_img+n_img)]\n",
    "reconstructed_mean = torch.tensor(mean_imputer.transform(data_with_nas_as_nas)).float().cpu()[range(start_img, start_img+n_img)]\n",
    "\n",
    "ground_truth = data_with_nas_2.unmissing_data[range(start_img, start_img+n_img)]\n",
    "corrupted = data_with_nas_2.data[range(start_img, start_img+n_img)]\n",
    "\n",
    "imputed_sdae = data_with_nas_2.unmissing_data[range(start_img, start_img+n_img)].clone()\n",
    "imputed_sdae[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1] = reconstructed_sdae[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1]\n",
    "imputed_bdae = data_with_nas_2.unmissing_data[range(start_img, start_img+n_img)].clone()\n",
    "imputed_bdae[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1] = reconstructed_bdae[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1]\n",
    "imputed_bvae = data_with_nas_2.unmissing_data[range(start_img, start_img+n_img)].clone()\n",
    "imputed_bvae[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1] = reconstructed_bvae[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1]\n",
    "imputed_mean = data_with_nas_2.unmissing_data[range(start_img, start_img+n_img)].clone()\n",
    "imputed_mean[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1] = reconstructed_mean[data_with_nas_2.targets[range(start_img, start_img+n_img)] == 1]\n",
    "\n",
    "fig, ax = plt.subplots(6, n_img, figsize=(10, 10))\n",
    "\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "\n",
    "for i in range(n_img):\n",
    "    ax[0, i].imshow(torch.unflatten(ground_truth, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[1, i].imshow(torch.unflatten(corrupted, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[2, i].imshow(torch.unflatten(imputed_sdae, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[3, i].imshow(torch.unflatten(imputed_bdae, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[4, i].imshow(torch.unflatten(imputed_bvae, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[5, i].imshow(torch.unflatten(imputed_mean, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "\n",
    "y_labels = ['Original', 'Corrupted', 'ImputeLM', 'DAE', 'VAE', 'Mean']\n",
    "\n",
    "for i in range(6):\n",
    "    ax[i, 0].set_ylabel(y_labels[i], rotation=90, labelpad=8, fontsize=12, va='center', ha='center')\n",
    "    ax[i, 0].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "    for spine in ['top', 'right', 'bottom', 'left']:\n",
    "        ax[i, 0].spines[spine].set_visible(False)\n",
    "\n",
    "for i in range(6):\n",
    "    for j in range(n_img):\n",
    "        ax[i, j].set_xticks([])\n",
    "        ax[i, j].set_yticks([])\n",
    "        ax[i, j].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "        if j != 0: \n",
    "            for spine in ['top', 'right', 'bottom', 'left']:\n",
    "                ax[i, j].spines[spine].set_visible(False)\n",
    "\n",
    "# Add title to plot\n",
    "plt.suptitle('Imputation Results on MNIST Digits', fontsize=16, y=0.95, ha='center')\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Denoising Autoencoder (Replication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_img = 25\n",
    "n_img = 8\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "\n",
    "\n",
    "ground_truth = data_without_nas_2.data[range(start_img, start_img+n_img)]\n",
    "corrupted = helper_noise.add_noise_with_model(noise_model=dae_noise, encoder=None, data=data_without_nas_2.data[range(start_img, start_img+n_img)], corruption_share=0.4, device=device)[0]\n",
    "reconstructed = torch.clip(model_bdae(corrupted.to(device)).detach(), 0, 1).cpu()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(3, n_img, figsize=(16, 6))\n",
    "\n",
    "sizes = [28, 28]\n",
    "sizes = [32, 32] if 'CIFAR10' in dcon['dataset'] else sizes\n",
    "\n",
    "for i in range(n_img):\n",
    "    ax[0, i].imshow(torch.unflatten(ground_truth, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[1, i].imshow(torch.unflatten(corrupted, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "    ax[2, i].imshow(torch.unflatten(reconstructed, dim=1, sizes=sizes)[i].cpu().float(), cmap='gray')\n",
    "\n",
    "\n",
    "# Labels for the y-axis\n",
    "y_labels = ['Original', 'Corrupted', 'Reconstructed']\n",
    "\n",
    "# Apply y-axis labels to the leftmost column\n",
    "for i in range(3):\n",
    "    ax[i, 0].set_ylabel(y_labels[i], rotation=90, labelpad=8, fontsize=12, va='center', ha='center')\n",
    "    ax[i, 0].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks and labels except y-axis labels\n",
    "    for spine in ['top', 'right', 'bottom', 'left']:\n",
    "        ax[i, 0].spines[spine].set_visible(False)\n",
    "\n",
    "# Hide all other axes elements and labels\n",
    "for i in range(3):\n",
    "    for j in range(n_img):\n",
    "        ax[i, j].set_xticks([])  # Hide x-axis ticks\n",
    "        ax[i, j].set_yticks([])  # Hide y-axis ticks\n",
    "        ax[i, j].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)  # Hide ticks and labels\n",
    "        if j != 0:  # Hide spines for all but the leftmost column\n",
    "            for spine in ['top', 'right', 'bottom', 'left']:\n",
    "                ax[i, j].spines[spine].set_visible(False)\n",
    "\n",
    "# Add title to plot\n",
    "plt.suptitle('Denoising Autoencoder Reconstructions', fontsize=16, y=0.95, ha='center')\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
